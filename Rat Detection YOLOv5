{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8047512,"sourceType":"datasetVersion","datasetId":4745274}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ragib310/rat-detection-yolov5?scriptVersionId=170805868\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Initialize constants","metadata":{}},{"cell_type":"markdown","source":"Set BASE_MODEL according to [Pretrained Checkpoints](https://github.com/ultralytics/yolov5/releases)","metadata":{}},{"cell_type":"code","source":"PROJECT_NAME = \"yolov5_train\"\nBASE_MODEL = \"yolov5m6.pt\"\nTRAIN_BATCH = 64\nTRAIN_EPOCHS = 100\nVAL_BATCH = 64\nprint('Initialization Done!')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:08:07.585865Z","iopub.execute_input":"2024-04-07T13:08:07.586248Z","iopub.status.idle":"2024-04-07T13:08:07.591945Z","shell.execute_reply.started":"2024-04-07T13:08:07.58622Z","shell.execute_reply":"2024-04-07T13:08:07.590968Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Clone yolov5 repo","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/yolov5\n!git clone https://github.com/ultralytics/yolov5","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:08:13.556852Z","iopub.execute_input":"2024-04-07T13:08:13.557246Z","iopub.status.idle":"2024-04-07T13:08:16.89207Z","shell.execute_reply.started":"2024-04-07T13:08:13.557218Z","shell.execute_reply":"2024-04-07T13:08:16.891032Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/yolov5\n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:08:21.323254Z","iopub.execute_input":"2024-04-07T13:08:21.32364Z","iopub.status.idle":"2024-04-07T13:08:37.066667Z","shell.execute_reply.started":"2024-04-07T13:08:21.3236Z","shell.execute_reply":"2024-04-07T13:08:37.06567Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"markdown","source":"This notebook contains steps to train and evaluate yolov5 model with custom data from scratch. \n\nSteps to reproduce:\n1. Collect lots of images.\n2. Label images using labeling tool.\n4. Train model and get weights file.\n5. Initialize model with weights file & use it.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom yolov5 import utils\nimport torch\nfrom IPython import display\nfrom IPython.display import clear_output\nfrom pathlib import Path\nimport yaml\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport glob\nimport io\nimport os\nimport cv2\nimport json\nimport shutil\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:09:23.427865Z","iopub.execute_input":"2024-04-07T13:09:23.428816Z","iopub.status.idle":"2024-04-07T13:09:28.216026Z","shell.execute_reply.started":"2024-04-07T13:09:23.428762Z","shell.execute_reply":"2024-04-07T13:09:28.21519Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Convert data to yolov5 Pytorch format\n\nPrepare data from Label Studio yolov5 darknet format to pytorch yolov5","metadata":{}},{"cell_type":"code","source":"IMAGES_PATH = \"/kaggle/input/rat-dataset-yolov5/rat_detection.v4i.yolov5pytorch/images\"\nLABELS_PATH = \"/kaggle/input/rat-dataset-yolov5/rat_detection.v4i.yolov5pytorch/labels\"\nNOTES_PATH = \"/kaggle/input/rat-dataset-yolov5/rat_detection.v4i.yolov5pytorch/notes.json\"","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:10:48.095887Z","iopub.execute_input":"2024-04-07T13:10:48.096902Z","iopub.status.idle":"2024-04-07T13:10:48.101384Z","shell.execute_reply.started":"2024-04-07T13:10:48.096866Z","shell.execute_reply":"2024-04-07T13:10:48.100477Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Read labels\nlabels = os.listdir(LABELS_PATH)\n\n# Split data\ntrain, test = train_test_split(labels, test_size=0.15, shuffle=True)\nvalid, test = train_test_split(test, test_size=0.2)\n\nprint(f\"train: {len(train)}; valid: {len(valid)}; test: {len(test)}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:10:51.105886Z","iopub.execute_input":"2024-04-07T13:10:51.10655Z","iopub.status.idle":"2024-04-07T13:10:51.214032Z","shell.execute_reply.started":"2024-04-07T13:10:51.106516Z","shell.execute_reply":"2024-04-07T13:10:51.213091Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Make dirs for pytorch dataset format","metadata":{}},{"cell_type":"code","source":"os.makedirs(\"test/images\")\nos.makedirs(\"test/labels\")\nos.makedirs(\"train/images\")\nos.makedirs(\"train/labels\")\nos.makedirs(\"valid/images\")\nos.makedirs(\"valid/labels\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:11:00.219568Z","iopub.execute_input":"2024-04-07T13:11:00.219944Z","iopub.status.idle":"2024-04-07T13:11:00.226689Z","shell.execute_reply.started":"2024-04-07T13:11:00.219905Z","shell.execute_reply":"2024-04-07T13:11:00.225739Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def move_files_to_dir(files, dirname):\n    for label_filename in files:\n        image_filename = f\"{label_filename[:-4]}.jpg\"\n        shutil.copy(f\"{IMAGES_PATH}/{image_filename}\", f\"{dirname}/images/{image_filename}\")\n        shutil.copy(f\"{LABELS_PATH}/{label_filename}\", f\"{dirname}/labels/{label_filename}\")\n\n# Move splits to folders\nmove_files_to_dir(train, \"train\")\nmove_files_to_dir(test, \"test\")\nmove_files_to_dir(valid, \"valid\")","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:11:02.572447Z","iopub.execute_input":"2024-04-07T13:11:02.573221Z","iopub.status.idle":"2024-04-07T13:11:32.154468Z","shell.execute_reply.started":"2024-04-07T13:11:02.573177Z","shell.execute_reply":"2024-04-07T13:11:32.153581Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Convert yolov5-darknet to yolov5-pytorch description file","metadata":{}},{"cell_type":"code","source":"descr_darknet = json.load(open(NOTES_PATH))\n\ntrain_path = \"../train/images\"\ntest_path = \"../test/images\"\nvalid_path = \"../valid/images\"\n\nnc = len(descr_darknet[\"categories\"])\nnames = [category[\"name\"] for category in descr_darknet[\"categories\"]]\n\nprint(\n    f\"train: {train_path}\\n\"\n    f\"test: {test_path}\\n\"\n    f\"val: {valid_path}\\n\\n\"\n    f\"nc: {nc}\\n\"\n    f\"names: {names}\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:12:04.965504Z","iopub.execute_input":"2024-04-07T13:12:04.965875Z","iopub.status.idle":"2024-04-07T13:12:04.975287Z","shell.execute_reply.started":"2024-04-07T13:12:04.965847Z","shell.execute_reply":"2024-04-07T13:12:04.974291Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"data.yaml\", \"w\") as file:\n    yaml.dump({\n        \"train\": train_path,\n        \"test\": test_path,\n        \"val\": valid_path,\n        \"nc\": nc,\n        \"names\": [f'{name}' for name in names]\n    }, stream=file, default_flow_style=None)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:12:06.639416Z","iopub.execute_input":"2024-04-07T13:12:06.640182Z","iopub.status.idle":"2024-04-07T13:12:06.646445Z","shell.execute_reply.started":"2024-04-07T13:12:06.640149Z","shell.execute_reply":"2024-04-07T13:12:06.64564Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Now we are ready to train yolov5 model\")\n! ls ","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:12:08.403584Z","iopub.execute_input":"2024-04-07T13:12:08.404346Z","iopub.status.idle":"2024-04-07T13:12:09.37078Z","shell.execute_reply.started":"2024-04-07T13:12:08.404315Z","shell.execute_reply":"2024-04-07T13:12:09.36964Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train yolov5","metadata":{}},{"cell_type":"code","source":"!python train.py --batch $TRAIN_BATCH --epochs $TRAIN_EPOCHS --data \"data.yaml\" --weights $BASE_MODEL --project $PROJECT_NAME --name 'feature_extraction' --cache --freeze 12","metadata":{"execution":{"iopub.status.busy":"2024-04-07T13:12:18.696345Z","iopub.execute_input":"2024-04-07T13:12:18.696738Z","iopub.status.idle":"2024-04-07T14:54:27.740515Z","shell.execute_reply.started":"2024-04-07T13:12:18.696706Z","shell.execute_reply":"2024-04-07T14:54:27.739421Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"WEIGHTS_BEST = f\"{PROJECT_NAME}/feature_extraction/weights/best.pt\"\n!python val.py --weights $WEIGHTS_BEST --batch $VAL_BATCH --data 'data.yaml' --task test --project $PROJECT_NAME --name 'validation_on_test_data' --augment","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:09:46.165324Z","iopub.execute_input":"2024-04-07T15:09:46.166347Z","iopub.status.idle":"2024-04-07T15:10:05.835161Z","shell.execute_reply.started":"2024-04-07T15:09:46.166301Z","shell.execute_reply":"2024-04-07T15:10:05.833957Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test detection","metadata":{}},{"cell_type":"code","source":"!python detect.py --weights $WEIGHTS_BEST --conf 0.5 --source 'test/images' --project $PROJECT_NAME --name 'detect_test' --augment --line=3","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:10:37.13117Z","iopub.execute_input":"2024-04-07T15:10:37.131583Z","iopub.status.idle":"2024-04-07T15:10:54.074811Z","shell.execute_reply.started":"2024-04-07T15:10:37.13155Z","shell.execute_reply":"2024-04-07T15:10:54.073818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_images(dirpath):\n  images = []\n  for img_filename in os.listdir(dirpath):\n    images.append(cv2.imread(f\"{dirpath}/{img_filename}\"))\n  return images","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:16:34.357251Z","iopub.execute_input":"2024-04-07T15:16:34.357926Z","iopub.status.idle":"2024-04-07T15:16:34.362939Z","shell.execute_reply.started":"2024-04-07T15:16:34.357881Z","shell.execute_reply":"2024-04-07T15:16:34.36205Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def label_test_images(test_images_path, test_labels_path, classes):\n  test_images = os.listdir(test_images_path)\n  labeled_images = []\n\n  for idx, test_image_filename in enumerate(test_images):\n    image = cv2.imread(f\"{test_images_path}/{test_image_filename}\")\n    \n    x_shape, y_shape = image.shape[1], image.shape[0]\n\n    test_label_filename = f\"{test_image_filename[:-4]}.txt\"\n    \n    with open(f\"{test_labels_path}/{test_label_filename}\", \"r\") as f:\n      lines = f.readlines()\n\n      for line in lines:\n        # Parse line\n        box = line.split()\n        class_idx = box[0]\n        \n        class_name = names[int(class_idx)]\n        x_center, y_center, box_w, box_h = int(float(box[1])*x_shape), int(float(box[2])*y_shape), int(float(box[3])*x_shape), int(float(box[3])*y_shape)\n        x1, y1, x2, y2 = x_center-int(box_w/2), y_center-int(box_h/2), x_center+int(box_w/2), y_center+int(box_h/2)\n\n        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 3)\n        cv2.putText(image, class_name, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)\n\n    labeled_images.append(image)\n\n  return labeled_images","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:16:36.922854Z","iopub.execute_input":"2024-04-07T15:16:36.923266Z","iopub.status.idle":"2024-04-07T15:16:36.933439Z","shell.execute_reply.started":"2024-04-07T15:16:36.923233Z","shell.execute_reply":"2024-04-07T15:16:36.932389Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detect_path = f\"{PROJECT_NAME}/detect_test\"\ntest_images_path = f\"test/images\"\ntest_labels_path = f\"test/labels\"\n\ndetected_images = read_images(detect_path)\ntest_labeled_images = label_test_images(test_images_path, test_labels_path, classes=names)\n\nstacked_images = [np.hstack([detected_images[idx], test_labeled_images[idx]]) for idx in range(len(detected_images))]","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:16:39.197763Z","iopub.execute_input":"2024-04-07T15:16:39.198174Z","iopub.status.idle":"2024-04-07T15:16:40.795798Z","shell.execute_reply.started":"2024-04-07T15:16:39.198144Z","shell.execute_reply":"2024-04-07T15:16:40.794764Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for image in stacked_images:\n  fig = plt.figure(figsize=(40, 15))\n  ax1 = fig.add_subplot(2,2,1)\n  ax1.imshow(image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save model","metadata":{}},{"cell_type":"markdown","source":"To save your model just download best.pt file from PROJECT_FOLDER -> feature_extraction (your best) -> weights -> best.pt\n\nFile best.pt will be used to load it in your project to predict.","metadata":{}}]}